{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1db4611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "from collections import Counter\n",
    "from math import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d21cfa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. LOAD & PREPROCESSING DATA\n",
    "def load_data():\n",
    "    # Nanti Akan Load Data dari Database\n",
    "    articles_df = pd.read_csv('data/articles_202505071725.csv')\n",
    "    likes_df = pd.read_csv('data/article_likes_202505071726.csv')\n",
    "    comments_df = pd.read_csv('data/article_comments_202505071727.csv')\n",
    "    return articles_df, likes_df, comments_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a47aa08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(articles_df, likes_df, comments_df):\n",
    "    \n",
    "      # Ensure all IDs are strings\n",
    "    articles_df['id'] = articles_df['id'].astype(str)\n",
    "    likes_df['article_id'] = likes_df['article_id'].astype(str)\n",
    "    comments_df['article_id'] = comments_df['article_id'].astype(str)\n",
    "    \n",
    "    # Calculate likes per article\n",
    "    article_likes = likes_df.groupby('article_id').size().reset_index(name='likes_count')\n",
    "    \n",
    "    # Calculate comments per article\n",
    "    article_comments = comments_df.groupby('article_id').size().reset_index(name='comments_count')\n",
    "    \n",
    "    # Combine data with articles\n",
    "    articles_enriched = articles_df.copy()\n",
    "    articles_enriched['id'] = articles_enriched['id'].astype(str)\n",
    "    \n",
    "    # Add likes count\n",
    "    articles_enriched = articles_enriched.merge(article_likes, left_on='id', right_on='article_id', how='left')\n",
    "    articles_enriched['likes_count'] = articles_enriched['likes_count'].fillna(0)\n",
    "    \n",
    "    # Add comments count\n",
    "    articles_enriched = articles_enriched.merge(article_comments, left_on='id', right_on='article_id', how='left')\n",
    "    articles_enriched['comments_count'] = articles_enriched['comments_count'].fillna(0)\n",
    "    \n",
    "    # Clean up\n",
    "    articles_enriched = articles_enriched.drop(['article_id_x', 'article_id_y'], axis=1, errors='ignore')\n",
    "    \n",
    "    # Extract features from article title using Text Processing\n",
    "    # Combine title, province, and city for text-based features\n",
    "    articles_enriched['text_features'] = articles_enriched['title'] + ' ' + articles_enriched['province'] + ' ' + articles_enriched['city']\n",
    "    \n",
    "    # Add engagement score\n",
    "    articles_enriched['engagement_score'] = articles_enriched['likes_count'] + (2 * articles_enriched['comments_count'])\n",
    "    \n",
    "    return articles_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a4e8b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFContentBasedRecommender:\n",
    "    def __init__(self):\n",
    "        self.vocab = {}\n",
    "        self.idf = {}\n",
    "        self.article_embeddings = None\n",
    "        self.articles_df = None\n",
    "        self.model = None\n",
    "        self.model_path = 'models/tf_content_recommender'\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        return text.lower().split()\n",
    "\n",
    "    def _build_vocab(self, texts):\n",
    "        vocab_counter = Counter()\n",
    "        for text in texts:\n",
    "            tokens = self._tokenize(text)\n",
    "            vocab_counter.update(tokens)\n",
    "        self.vocab = {word: idx for idx, (word, _) in enumerate(vocab_counter.items())}\n",
    "    \n",
    "    def _compute_idf(self, texts):\n",
    "        N = len(texts)\n",
    "        df = Counter()\n",
    "        for text in texts:\n",
    "            tokens = set(self._tokenize(text))\n",
    "            df.update(tokens)\n",
    "        self.idf = {word: log(N / (df[word] + 1)) for word in self.vocab}\n",
    "\n",
    "    def _tfidf_vector(self, text):\n",
    "        tokens = self._tokenize(text)\n",
    "        tf = Counter(tokens)\n",
    "        vector = np.zeros(len(self.vocab))\n",
    "        for token in tokens:\n",
    "            if token in self.vocab:\n",
    "                tf_val = tf[token] / len(tokens)\n",
    "                idf_val = self.idf.get(token, 0)\n",
    "                vector[self.vocab[token]] = tf_val * idf_val\n",
    "        return vector\n",
    "\n",
    "    def _build_model(self, input_dim):\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "            tf.keras.layers.Dense(64, activation='relu')\n",
    "        ])\n",
    "        return model\n",
    "\n",
    "    def fit(self, articles_df):\n",
    "        self.articles_df = articles_df.copy()\n",
    "        texts = self.articles_df['text_features'].tolist()\n",
    "\n",
    "        self._build_vocab(texts)\n",
    "        self._compute_idf(texts)\n",
    "\n",
    "        tfidf_matrix = np.array([self._tfidf_vector(text) for text in texts])\n",
    "        self.model = self._build_model(input_dim=tfidf_matrix.shape[1])\n",
    "        self.article_embeddings = self.model.predict(tfidf_matrix)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def recommend(self, article_id, top_n=5):\n",
    "        idx = self.articles_df[self.articles_df['id'] == article_id].index[0]\n",
    "        query_embedding = self.article_embeddings[idx].reshape(1, -1)\n",
    "\n",
    "        similarity = np.dot(self.article_embeddings, query_embedding.T).flatten()\n",
    "        norms = np.linalg.norm(self.article_embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "        similarity = similarity / norms\n",
    "\n",
    "        sim_indices = np.argsort(similarity)[::-1][1:top_n+1]\n",
    "        recommended_articles = self.articles_df.iloc[sim_indices][['id', 'title', 'province', 'city']].copy()\n",
    "        recommended_articles['similarity_score'] = similarity[sim_indices]\n",
    "\n",
    "        return recommended_articles\n",
    "\n",
    "    def save_model(self):\n",
    "        os.makedirs(self.model_path, exist_ok=True)\n",
    "        np.save(os.path.join(self.model_path, 'article_embeddings.npy'), self.article_embeddings)\n",
    "        self.articles_df.to_pickle(os.path.join(self.model_path, 'articles_df.pkl'))\n",
    "\n",
    "        with open(os.path.join(self.model_path, 'vocab.json'), 'w') as f:\n",
    "            json.dump(self.vocab, f)\n",
    "        with open(os.path.join(self.model_path, 'idf.json'), 'w') as f:\n",
    "            json.dump(self.idf, f)\n",
    "\n",
    "    def load_model(self):\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.article_embeddings = np.load(os.path.join(self.model_path, 'article_embeddings.npy'))\n",
    "            self.articles_df = pd.read_pickle(os.path.join(self.model_path, 'articles_df.pkl'))\n",
    "\n",
    "            with open(os.path.join(self.model_path, 'vocab.json'), 'r') as f:\n",
    "                self.vocab = json.load(f)\n",
    "            with open(os.path.join(self.model_path, 'idf.json'), 'r') as f:\n",
    "                self.idf = json.load(f)\n",
    "\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def update_model(self, new_articles_df):\n",
    "        if self.articles_df is not None:\n",
    "            existing_uuids = set(self.articles_df['id'].values)\n",
    "            new_articles = new_articles_df[~new_articles_df['id'].isin(existing_uuids)]\n",
    "\n",
    "            if len(new_articles) > 0:\n",
    "                self.articles_df = pd.concat([self.articles_df, new_articles]).reset_index(drop=True)\n",
    "                self.fit(self.articles_df)\n",
    "                self.save_model()\n",
    "                return True, f\"Model updated with {len(new_articles)} new articles\"\n",
    "            return False, \"No new articles to update\"\n",
    "        else:\n",
    "            self.fit(new_articles_df)\n",
    "            self.save_model()\n",
    "            return True, f\"Initial model created with {len(new_articles_df)} articles\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1593cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat data\n",
    "articles, likes, comments = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cc69ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil kolom-kolom yang diinginkan dari DataFrame\n",
    "articles_df = articles[['id', 'title', 'slug', 'province', 'city', 'active', 'user_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc872878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>slug</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>active</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Might group board positive campaign per partic...</td>\n",
       "      <td>arm-happy-book-win</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Estradaborough</td>\n",
       "      <td>True</td>\n",
       "      <td>d50e8d4f-871d-4ef9-9a7f-d360180588a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Build someone around eight past chance.</td>\n",
       "      <td>nothing-same-hand</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>Reidberg</td>\n",
       "      <td>True</td>\n",
       "      <td>ba2372f3-5250-402a-ab7d-4012b924c020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Realize strong simply attorney.</td>\n",
       "      <td>data-skin-from</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>North Ronaldberg</td>\n",
       "      <td>True</td>\n",
       "      <td>d4b08900-100d-426f-8dff-5f8ddc134485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Allow million school.</td>\n",
       "      <td>study-view-wish</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>West Brandonview</td>\n",
       "      <td>True</td>\n",
       "      <td>0f9cbb49-8e26-4f8b-9306-d810710feb87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Push stage need officer process.</td>\n",
       "      <td>notice-attack-kid</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>West Cynthiaview</td>\n",
       "      <td>True</td>\n",
       "      <td>755c75c2-2642-471a-93d1-13d7920d5530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>3996</td>\n",
       "      <td>Again above box.</td>\n",
       "      <td>american-commercial</td>\n",
       "      <td>Utah</td>\n",
       "      <td>North Barbarastad</td>\n",
       "      <td>True</td>\n",
       "      <td>57480c0a-91c2-4067-9e5f-bac77e2fc557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>3997</td>\n",
       "      <td>Likely bit they into once.</td>\n",
       "      <td>student-site-line</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Jackport</td>\n",
       "      <td>True</td>\n",
       "      <td>28634318-d553-4ca7-8d85-c76012a9ea1c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>3998</td>\n",
       "      <td>Condition cut too somebody back couple approac...</td>\n",
       "      <td>old-response-late</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>Matthewburgh</td>\n",
       "      <td>True</td>\n",
       "      <td>947aeccc-feca-4c40-af8c-683d019f7539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>3999</td>\n",
       "      <td>Trial evening indicate follow put yourself spe...</td>\n",
       "      <td>force-name-husband</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Port Shelleyport</td>\n",
       "      <td>True</td>\n",
       "      <td>52f865af-89ed-450b-8c25-8396a628dfd3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>4000</td>\n",
       "      <td>Wide suffer sell need himself quite perform.</td>\n",
       "      <td>firm-political</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>Port Allison</td>\n",
       "      <td>True</td>\n",
       "      <td>970ea908-e752-4494-a5c1-7c89efe8dcf3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0        1  Might group board positive campaign per partic...   \n",
       "1        2            Build someone around eight past chance.   \n",
       "2        3                    Realize strong simply attorney.   \n",
       "3        4                              Allow million school.   \n",
       "4        5                   Push stage need officer process.   \n",
       "...    ...                                                ...   \n",
       "3995  3996                                   Again above box.   \n",
       "3996  3997                         Likely bit they into once.   \n",
       "3997  3998  Condition cut too somebody back couple approac...   \n",
       "3998  3999  Trial evening indicate follow put yourself spe...   \n",
       "3999  4000       Wide suffer sell need himself quite perform.   \n",
       "\n",
       "                     slug        province               city  active  \\\n",
       "0      arm-happy-book-win  North Carolina     Estradaborough    True   \n",
       "1       nothing-same-hand           Idaho           Reidberg    True   \n",
       "2          data-skin-from       Tennessee   North Ronaldberg    True   \n",
       "3         study-view-wish          Oregon   West Brandonview    True   \n",
       "4       notice-attack-kid        Delaware   West Cynthiaview    True   \n",
       "...                   ...             ...                ...     ...   \n",
       "3995  american-commercial            Utah  North Barbarastad    True   \n",
       "3996    student-site-line        Michigan           Jackport    True   \n",
       "3997    old-response-late        Oklahoma       Matthewburgh    True   \n",
       "3998   force-name-husband    Pennsylvania   Port Shelleyport    True   \n",
       "3999       firm-political   New Hampshire       Port Allison    True   \n",
       "\n",
       "                                   user_id  \n",
       "0     d50e8d4f-871d-4ef9-9a7f-d360180588a3  \n",
       "1     ba2372f3-5250-402a-ab7d-4012b924c020  \n",
       "2     d4b08900-100d-426f-8dff-5f8ddc134485  \n",
       "3     0f9cbb49-8e26-4f8b-9306-d810710feb87  \n",
       "4     755c75c2-2642-471a-93d1-13d7920d5530  \n",
       "...                                    ...  \n",
       "3995  57480c0a-91c2-4067-9e5f-bac77e2fc557  \n",
       "3996  28634318-d553-4ca7-8d85-c76012a9ea1c  \n",
       "3997  947aeccc-feca-4c40-af8c-683d019f7539  \n",
       "3998  52f865af-89ed-450b-8c25-8396a628dfd3  \n",
       "3999  970ea908-e752-4494-a5c1-7c89efe8dcf3  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "396bb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil kolom-kolom yang diinginkan dari DataFrame\n",
    "comments_df = comments[['id', 'article_id', 'user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e1307c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51f47a74-5963-4578-b457-caac6e2a13e9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a79d17b3-17fd-4102-ae4a-6b74c8b343e2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8fb9249a-eb00-47be-8581-27b64a974e4a</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c222b802-a46c-4c61-817b-3f7213824af4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c2566f5d-2016-485e-a7a8-2dc8a2f5862e</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>d7bb2185-93f6-4a61-abae-877f53fa3b8e</td>\n",
       "      <td>3996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>2c02e141-1d36-403d-b9ed-9ea86e2d2d84</td>\n",
       "      <td>3997</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>5b56536d-b693-46ba-8b62-f1b2e832abc5</td>\n",
       "      <td>3998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>472514e4-26bd-4f18-ac17-fea3e025cfc4</td>\n",
       "      <td>3999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>81754b0a-6205-47d5-aff3-525f499bbb91</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  article_id  user_id\n",
       "0     51f47a74-5963-4578-b457-caac6e2a13e9           1        1\n",
       "1     a79d17b3-17fd-4102-ae4a-6b74c8b343e2           2        2\n",
       "2     8fb9249a-eb00-47be-8581-27b64a974e4a           3        1\n",
       "3     c222b802-a46c-4c61-817b-3f7213824af4           4        2\n",
       "4     c2566f5d-2016-485e-a7a8-2dc8a2f5862e           5        1\n",
       "...                                    ...         ...      ...\n",
       "3995  d7bb2185-93f6-4a61-abae-877f53fa3b8e        3996        1\n",
       "3996  2c02e141-1d36-403d-b9ed-9ea86e2d2d84        3997        3\n",
       "3997  5b56536d-b693-46ba-8b62-f1b2e832abc5        3998        3\n",
       "3998  472514e4-26bd-4f18-ac17-fea3e025cfc4        3999        4\n",
       "3999  81754b0a-6205-47d5-aff3-525f499bbb91        4000        1\n",
       "\n",
       "[4000 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d3015cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambil kolom-kolom yang diinginkan dari DataFrame\n",
    "likes_df = likes[['id', 'article_id', 'user_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03ef28aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f2d39235-dc3f-45f6-aa28-e9a5b743a2c9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80aa4790-8a72-4498-bb39-d8fd3f590b02</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24b8ace1-1dd1-4d4c-a507-ce6fbe1cfefa</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8b588322-5b48-4546-8afe-61344e1f9bff</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8b12918c-099d-4f33-a9bb-8dec217e1779</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>f4fcb644-2246-41d2-b677-464566a095f8</td>\n",
       "      <td>3996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>2bd1173e-a1f3-41d3-a150-20f0afa59d1d</td>\n",
       "      <td>3997</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>eff3ae86-7d90-41e0-a52e-0a278f36dfb4</td>\n",
       "      <td>3998</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>1b85c544-04cb-4ad4-8eea-cac9bb5a4eca</td>\n",
       "      <td>3999</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>5d066a91-3ef5-4984-bfaa-332b1c3d50a7</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        id  article_id  user_id\n",
       "0     f2d39235-dc3f-45f6-aa28-e9a5b743a2c9           1        2\n",
       "1     80aa4790-8a72-4498-bb39-d8fd3f590b02           2        2\n",
       "2     24b8ace1-1dd1-4d4c-a507-ce6fbe1cfefa           3        2\n",
       "3     8b588322-5b48-4546-8afe-61344e1f9bff           4        2\n",
       "4     8b12918c-099d-4f33-a9bb-8dec217e1779           5        2\n",
       "...                                    ...         ...      ...\n",
       "7995  f4fcb644-2246-41d2-b677-464566a095f8        3996        1\n",
       "7996  2bd1173e-a1f3-41d3-a150-20f0afa59d1d        3997        3\n",
       "7997  eff3ae86-7d90-41e0-a52e-0a278f36dfb4        3998        3\n",
       "7998  1b85c544-04cb-4ad4-8eea-cac9bb5a4eca        3999        4\n",
       "7999  5d066a91-3ef5-4984-bfaa-332b1c3d50a7        4000        1\n",
       "\n",
       "[8000 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "022e70dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MID-020\\AppData\\Local\\Temp\\ipykernel_18960\\1595832517.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  articles_df['id'] = articles_df['id'].astype(str)\n",
      "C:\\Users\\MID-020\\AppData\\Local\\Temp\\ipykernel_18960\\1595832517.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  likes_df['article_id'] = likes_df['article_id'].astype(str)\n",
      "C:\\Users\\MID-020\\AppData\\Local\\Temp\\ipykernel_18960\\1595832517.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments_df['article_id'] = comments_df['article_id'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "# Proses data\n",
    "articles_enriched = preprocess_data(articles_df, likes_df, comments_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1801fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>slug</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>active</th>\n",
       "      <th>user_id</th>\n",
       "      <th>likes_count</th>\n",
       "      <th>comments_count</th>\n",
       "      <th>text_features</th>\n",
       "      <th>engagement_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Might group board positive campaign per partic...</td>\n",
       "      <td>arm-happy-book-win</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>Estradaborough</td>\n",
       "      <td>True</td>\n",
       "      <td>d50e8d4f-871d-4ef9-9a7f-d360180588a3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Might group board positive campaign per partic...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Build someone around eight past chance.</td>\n",
       "      <td>nothing-same-hand</td>\n",
       "      <td>Idaho</td>\n",
       "      <td>Reidberg</td>\n",
       "      <td>True</td>\n",
       "      <td>ba2372f3-5250-402a-ab7d-4012b924c020</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Build someone around eight past chance. Idaho ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Realize strong simply attorney.</td>\n",
       "      <td>data-skin-from</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>North Ronaldberg</td>\n",
       "      <td>True</td>\n",
       "      <td>d4b08900-100d-426f-8dff-5f8ddc134485</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Realize strong simply attorney. Tennessee Nort...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Allow million school.</td>\n",
       "      <td>study-view-wish</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>West Brandonview</td>\n",
       "      <td>True</td>\n",
       "      <td>0f9cbb49-8e26-4f8b-9306-d810710feb87</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Allow million school. Oregon West Brandonview</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Push stage need officer process.</td>\n",
       "      <td>notice-attack-kid</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>West Cynthiaview</td>\n",
       "      <td>True</td>\n",
       "      <td>755c75c2-2642-471a-93d1-13d7920d5530</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Push stage need officer process. Delaware West...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                              title                slug  \\\n",
       "0  1  Might group board positive campaign per partic...  arm-happy-book-win   \n",
       "1  2            Build someone around eight past chance.   nothing-same-hand   \n",
       "2  3                    Realize strong simply attorney.      data-skin-from   \n",
       "3  4                              Allow million school.     study-view-wish   \n",
       "4  5                   Push stage need officer process.   notice-attack-kid   \n",
       "\n",
       "         province              city  active  \\\n",
       "0  North Carolina    Estradaborough    True   \n",
       "1           Idaho          Reidberg    True   \n",
       "2       Tennessee  North Ronaldberg    True   \n",
       "3          Oregon  West Brandonview    True   \n",
       "4        Delaware  West Cynthiaview    True   \n",
       "\n",
       "                                user_id  likes_count  comments_count  \\\n",
       "0  d50e8d4f-871d-4ef9-9a7f-d360180588a3            2               1   \n",
       "1  ba2372f3-5250-402a-ab7d-4012b924c020            2               1   \n",
       "2  d4b08900-100d-426f-8dff-5f8ddc134485            2               1   \n",
       "3  0f9cbb49-8e26-4f8b-9306-d810710feb87            2               1   \n",
       "4  755c75c2-2642-471a-93d1-13d7920d5530            2               1   \n",
       "\n",
       "                                       text_features  engagement_score  \n",
       "0  Might group board positive campaign per partic...                 4  \n",
       "1  Build someone around eight past chance. Idaho ...                 4  \n",
       "2  Realize strong simply attorney. Tennessee Nort...                 4  \n",
       "3      Allow million school. Oregon West Brandonview                 4  \n",
       "4  Push stage need officer process. Delaware West...                 4  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a57fd85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TFContentBasedRecommender at 0x1846121bc80>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inisialisasi model Content-Based Recommender\n",
    "recommender = TFContentBasedRecommender()\n",
    "recommender.fit(articles_enriched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c427b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rekomendasi untuk artikel 'Build someone around eight past chance.':\n",
      "- Sea bar around indeed drop positive. (Skor: 0.8268)\n",
      "- Local event peace parent leg head. (Skor: 0.8154)\n",
      "- Throughout four tax chance might. (Skor: 0.8080)\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan rekomendasi\n",
    "article_id = '2'  # ID artikel referensi\n",
    "recommendations = recommender.recommend(article_id, top_n=3)\n",
    "    \n",
    "print(f\"Rekomendasi untuk artikel '{articles_df[articles_df['id'] == article_id]['title'].values[0]}':\")\n",
    "for _, row in recommendations.iterrows():\n",
    "    print(f\"- {row['title']} (Skor: {row['similarity_score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4dfb0a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artikel yang direkomendasikan:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>province</th>\n",
       "      <th>city</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>3440</td>\n",
       "      <td>Player reach eye situation treat report art.</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>South Tamara</td>\n",
       "      <td>0.832967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>3034</td>\n",
       "      <td>Participant head voice identify attention turn.</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>North Carla</td>\n",
       "      <td>0.804139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>643</td>\n",
       "      <td>Trade popular commercial collection hand.</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>Lake Tylermouth</td>\n",
       "      <td>0.800131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3292</th>\n",
       "      <td>3293</td>\n",
       "      <td>Network sport offer likely usually.</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>North Denise</td>\n",
       "      <td>0.789957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>273</td>\n",
       "      <td>Simple series daughter play indeed country ahe...</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>West Christian</td>\n",
       "      <td>0.784626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title        province  \\\n",
       "3439  3440       Player reach eye situation treat report art.         Alabama   \n",
       "3033  3034    Participant head voice identify attention turn.          Hawaii   \n",
       "643    643          Trade popular commercial collection hand.       Tennessee   \n",
       "3292  3293                Network sport offer likely usually.        Missouri   \n",
       "273    273  Simple series daughter play indeed country ahe...  North Carolina   \n",
       "\n",
       "                 city  similarity_score  \n",
       "3439     South Tamara          0.832967  \n",
       "3033      North Carla          0.804139  \n",
       "643   Lake Tylermouth          0.800131  \n",
       "3292     North Denise          0.789957  \n",
       "273    West Christian          0.784626  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Memberikan rekomendasi artikel berdasarkan artikel dengan UUID tertentu\n",
    "article_id = '1'\n",
    "recommended_articles = recommender.recommend(article_id=article_id, top_n=5)\n",
    "print(\"Artikel yang direkomendasikan:\")\n",
    "recommended_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7404cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menyimpan model\n",
    "recommender.save_model()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
